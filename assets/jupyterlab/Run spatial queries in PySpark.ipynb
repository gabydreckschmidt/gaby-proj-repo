{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Run spatial queries in PySpark</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook shows you show to use use spatial queries in Spark environments. The notebook uses the spatio-temporal library that is pre-installed on all Spark environments in Watson Studio. You will learn how to perform common spatial queries in Spark. \n",
    "\n",
    "The types of spatial queries you will learn to use are:\n",
    "- In a set of points, find all the points that are within a certain distance to a particular point. For example, find all the hospitals that are within a certain distance to a given location.\n",
    "- In a set of polygons, find all the polygons that contain a particular point. For example, find all the risk areas for fires, floods, or hurricanes that contain a particular location.\n",
    "- In a set of points, find all the points that are contained within a particular polygon. For example, find all the retail outlets in a particular region.\n",
    "\n",
    "Often, a spatial function has one parameter that refers to a spatial column in one table and a second parameter that refers to a spatial constant or to a spatial column in another table. This notebook shows you how to use functions to access and combine data of different types to perform spatial queries.\n",
    "\n",
    "This notebook runs on Python 3.6 with Spark.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "1.\t[Register the Spark SQL spatial functions](#register)\n",
    "2.\t[Get sample data](#getData)\n",
    "3.\t[Create a geometry column](#createColumn)\n",
    "4.\t[Register the data frames](#registerDataframe)\n",
    "5.  [Run spatial queries](#runQueries)  \n",
    "6.\t[Summary](#summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"register\"></a>\n",
    "## 1. Register the Spark SQL spatial functions\n",
    "\n",
    "Register the Spark SQL spatial functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d28ba0bf9e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSqlGeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregisterAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark._jvm.org.apache.spark.sql.types.SqlGeometry.registerAll(spark._jsparkSession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getData\"></a>\n",
    "## 2. Get sample data\n",
    "\n",
    "This notebook uses a sample data set that is available in the IBM Watson Studio Gallery.\n",
    "\n",
    "1. Click [<name_of_data_set>](<link_to_the_data_set))to access the data set in the Watson Studio Gallery.\n",
    "2. Click **Add to project** and select your project. \n",
    "   The data file will be added to the selected project's Assets page as a data asset. \n",
    "3. Click the Find and add data icon from this notebook's action bar. On the files tab, you will see the sample file you added to the project.\n",
    "4. To load the data from the file into a data frame, click in the next code cell and select **Insert to code > Insert SparkSession  DataFrame** under the file name.\n",
    "\n",
    "Note: The data frame that is created for you and filled with data is given a generic name (`df_data_1`). Rename the data frame to `hospital_df`  and run the code cell to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the hospital data where each hospital's location is a latitude-longitude point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------+------------+-----+----------+---------+\n",
      "|id |name                         |city        |state|lon       |lat      |\n",
      "+---+-----------------------------+------------+-----+----------+---------+\n",
      "|1  |Southern Hills Medical Center|BERRY HILL  |TN   |-86.721939|36.077843|\n",
      "|2  |Sycamore Shoals Hospital     |ELIZABETHTON|TN   |-82.247635|36.346218|\n",
      "|3  |Tokona Hospital              |GREENEVILLE |TN   |-82.845711|36.151772|\n",
      "+---+-----------------------------+------------+-----+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-e4954516-f3e2-4418-aca0-ee9ee4bebca0',\n",
    "    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'api_key': 'mUL3zgMRm9hpmwclEPyYiEa_qbtA1aijcdjjZGSquEvY'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_79ac2ad149064ac5a2fb7c7fc32ada05_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "hospital_df = spark.read.csv(cos.url('hospitals.csv', 'spatiotemporalpythonexamples-donotdelete-pr-1ph9s1kbmrodxt'), header=True)\n",
    "\n",
    "hospital_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the county data where each county is a polygon/multipolygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|             name|           shape_wkt|\n",
      "+-----------------+--------------------+\n",
      "|Lake of the Woods|MULTIPOLYGON (((-...|\n",
      "|            Ferry|MULTIPOLYGON (((-...|\n",
      "|          Stevens|MULTIPOLYGON (((-...|\n",
      "+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "county_df = spark.read.csv(cos.url('counties_WKT_with_header.csv', 'spatiotemporalpythonexamples-donotdelete-pr-1ph9s1kbmrodxt'), header=True)\n",
    "county_df.select('name', 'shape_wkt').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"createColumn\"></a>\n",
    "## 3. Create a geometry column for hospital and county data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw spatial data in the data frame can be of various types, for example **columns indicating lat and lon** or **column indicating wkt string for the geometry**, and so on.\n",
    "\n",
    "Therefore, the first step is to use a spatial query to generate a new spatial column that combines the data in these columns.  \n",
    "For example, use the function:\n",
    "- `ST_Point(lon_col, lat_col)` if the raw spatial data is in a latitude column and a longitude column  \n",
    "- `ST_WKTTOSQL(wkt_col)` if the raw spatial data is in a column containing the wkt string form of the geometry  \n",
    "\n",
    "For the full list of possible query functions, see [Geospatial Toolkit functions](https://www.ibm.com/support/knowledgecenter/en/SSCJDQ/com.ibm.swg.im.dashdb.analytics.doc/doc/geo_functions.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a geometry column for the hospital data using `ST_Point(lon, lat)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------+------------+-----+----------+---------+---------------------------------------+\n",
      "|id |name                         |city        |state|lon       |lat      |location                               |\n",
      "+---+-----------------------------+------------+-----+----------+---------+---------------------------------------+\n",
      "|1  |Southern Hills Medical Center|BERRY HILL  |TN   |-86.721939|36.077843|PointEG: lat=36.077843, long=-86.721939|\n",
      "|2  |Sycamore Shoals Hospital     |ELIZABETHTON|TN   |-82.247635|36.346218|PointEG: lat=36.346218, long=-82.247635|\n",
      "|3  |Tokona Hospital              |GREENEVILLE |TN   |-82.845711|36.151772|PointEG: lat=36.151772, long=-82.845711|\n",
      "+---+-----------------------------+------------+-----+----------+---------+---------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hospital_df.createOrReplaceTempView(\"hospitals\")\n",
    "hospital_df = spark.sql(\"SELECT *, ST_Point(lon, lat) as location from hospitals\")\n",
    "hospital_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a geometry column for the county data using `ST_WKTToSQL(wkt_string)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-------+--------------------+\n",
      "|             NAME|STATE_NAME|POP2000|               shape|\n",
      "+-----------------+----------+-------+--------------------+\n",
      "|Lake of the Woods| Minnesota|   4522|AcceleratedMultiP...|\n",
      "|            Ferry|Washington|   7260|AcceleratedMultiP...|\n",
      "|          Stevens|Washington|  40066|AcceleratedMultiP...|\n",
      "+-----------------+----------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "county_df.createOrReplaceTempView('counties')\n",
    "county_df = spark.sql(\"SELECT NAME, STATE_NAME, POP2000, ST_WKTToSQL(shape_WKT) as shape from counties\")\n",
    "county_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"registerDataframe\"></a>\n",
    "## 4. Register the hospital and county data frames as a temporary view\n",
    "\n",
    "A data frame can also be used to create a temporary view. Registering a data frame as a table allows you to run SQL queries over its data. Register the hospital and county data frames as a temporary view: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.createOrReplaceTempView('hospitals')\n",
    "county_df.createOrReplaceTempView('counties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runQueries\"></a>\n",
    "## 5. Run spatial queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Query to determine points closest to another point\n",
    "\n",
    "This sample query shows you how to find the hospitals that are within a certain distance of a given location (which is constructed using the ST_Point constructor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+\n",
      "|                name|       city|state|\n",
      "+--------------------+-----------+-----+\n",
      "|Park Avenue Hospital|   BRIGHTON|   NY|\n",
      "|County Home and I...|   BRIGHTON|   NY|\n",
      "|    Genesee Hospital|   BRIGHTON|   NY|\n",
      "|   Highland Hospital|   BRIGHTON|   NY|\n",
      "|Rochester General...|IRONDEQUOIT|   NY|\n",
      "|Saint Marys Hospital|   BRIGHTON|   NY|\n",
      "|Strong Memorial H...|   BRIGHTON|   NY|\n",
      "+--------------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, city, state\n",
    "FROM hospitals\n",
    "WHERE ST_Distance(location, ST_Point(-77.574722, 43.146732)) < 10000.0\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Queries to determine which polygon contains a point\n",
    "\n",
    "The following sample queries show you how to use spatial functions to determine which polygon contains a given point. The examples use the following functions:\n",
    "\n",
    "1. `ST_Contains(geom1, geom2)`: This function returns TRUE if the `geom2` values are completely contained by the polygons identified by `geom1`.\n",
    "2. `ST_Within(geom1, geom2)`: This function returns TRUE if the `geom1` values are within the polygons identified by `geom2`.\n",
    "3. `ST_Intersects(geom1, geom2)`: This function returns TRUE if `geom1` and `geom2` intersect spatially in any way. This can be that they  touch, cross, or contain each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT NAME \n",
    "FROM counties \n",
    "WHERE ST_Contains(shape, ST_Point(-74.237, 42.037))\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  NAME|\n",
      "+------+\n",
      "|Ulster|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT NAME\n",
    "FROM counties\n",
    "WHERE\n",
    "ST_Within(ST_Point(-74.237, 42.037), shape)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  NAME|\n",
      "+------+\n",
      "|Ulster|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT NAME\n",
    "FROM counties\n",
    "WHERE\n",
    "ST_Intersects(shape, ST_Point(-74.237, 42.037))\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Queries to determine the points in a polygon\n",
    "\n",
    "Each of the following queries determines which hospitals are located within the specified polygon, which is defined as a constant using the  well-known text (WKT) representation. The polygon definition consists of the character string POLYGON followed by a pair of x,y coordinates for each vertex, separated by a comma. The individual x and y values are separated by a space. The entire list of coordinate pairs must be in parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE\n",
    "ST_Contains(ST_WKTToSQL('POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'), location)\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name \n",
    "FROM hospitals \n",
    "WHERE ST_Within(location, ST_WKTToSQL('POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name \n",
    "FROM hospitals \n",
    "WHERE ST_Intersects(location, ST_WKTToSQL('POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Spatial join queries to determine points in a polygon\n",
    "\n",
    "Just as a regular join function can join two tables based on the values in columns that contain character or numeric data, spatial join functions can be used to join tables based on the values in the columns that contain spatial data. The following examples use the **counties** and **hospitals** tables.\n",
    "\n",
    "You can use the spatial join function to find the hospitals located within a specific county. For example, the following query returns a list of all the hospitals in Dutchess county:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|    NAME|                name|\n",
      "+--------+--------------------+\n",
      "|Dutchess|Hudson River Stat...|\n",
      "|Dutchess|Vassar Brothers H...|\n",
      "|Dutchess|      Bowne Hospital|\n",
      "|Dutchess|Harlem Valley Sta...|\n",
      "|Dutchess|Matteawan State H...|\n",
      "|Dutchess|New York State Ho...|\n",
      "|Dutchess|Saint Francis Hos...|\n",
      "|Dutchess|United States Vet...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name \n",
    "FROM counties AS c, hospitals AS h \n",
    "WHERE c.NAME = 'Dutchess' \n",
    "AND ST_Intersects(c.shape, h.location)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the SQL `JOIN ... ON ...` notation, which is equivalent to a spatial predicate in the WHERE clause. For example, the following query produces the same result set as the previous query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|    NAME|\n",
      "+--------------------+--------+\n",
      "|Hudson River Stat...|Dutchess|\n",
      "|Vassar Brothers H...|Dutchess|\n",
      "|      Bowne Hospital|Dutchess|\n",
      "|Harlem Valley Sta...|Dutchess|\n",
      "|Matteawan State H...|Dutchess|\n",
      "|New York State Ho...|Dutchess|\n",
      "|Saint Francis Hos...|Dutchess|\n",
      "|United States Vet...|Dutchess|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT h.name, c.NAME\n",
    "FROM counties AS c\n",
    "JOIN hospitals AS h\n",
    "ON c.NAME = 'Dutchess'\n",
    "AND ST_Intersects(h.location, c.shape)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query returns the name of the county in which a particular hospital is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|    NAME|                name|\n",
      "+--------+--------------------+\n",
      "|Dutchess|Vassar Brothers H...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name\n",
    "FROM hospitals AS h, counties AS c\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND h.name = 'Vassar Brothers Hospital'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Spatial join queries with additional predicates and aggregation\n",
    "\n",
    "This example shows you how to use spatial joins in conjunction with additional predicates and aggregation, which can address business problems. These examples continue to use the hospitals and counties tables, but the same principles could be applied to any other type of data.\n",
    "\n",
    "The following example queries the hospitals within each county in New York state, qualifying by the state name in the counties table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|  NAME|                name|\n",
      "+------+--------------------+\n",
      "|Albany|     Albany Hospital|\n",
      "|Albany|Albany Hospital F...|\n",
      "|Albany|Albany Hospital S...|\n",
      "+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name\n",
    "FROM counties AS c, hospitals AS h\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND c.STATE_NAME='New York'\n",
    "ORDER BY c.NAME, h.name\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same results can be obtained by rewriting the above query and using the field from the hospitals table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|  NAME|                name|\n",
      "+------+--------------------+\n",
      "|Albany|     Albany Hospital|\n",
      "|Albany|Albany Hospital F...|\n",
      "|Albany|Albany Hospital S...|\n",
      "+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name\n",
    "FROM hospitals AS h, counties AS c\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND h.state='NY'\n",
    "ORDER BY c.NAME, h.name\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example lists the number of hospitals per county in New York:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|  NAME|hospital_count|\n",
      "+------+--------------+\n",
      "|Cayuga|             1|\n",
      "| Kings|            26|\n",
      "|Monroe|             9|\n",
      "+------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, COUNT(h.name) AS hospital_count\n",
    "FROM counties AS c, hospitals AS h\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND c.STATE_NAME='New York'\n",
    "GROUP BY c.NAME\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify counties where the population is underserved by hospitals, an interesting metric might be the number of people per hospital in each county. Using the population of each county in the year 2000, you can calculate this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------+-------------------+\n",
      "|      NAME|hospital_count|Population|people_per_hospital|\n",
      "+----------+--------------+----------+-------------------+\n",
      "|     Bronx|             9|   1332650| 148072.22222222222|\n",
      "|Chautauqua|             1|    139750|           139750.0|\n",
      "|    Oswego|             1|    122377|           122377.0|\n",
      "+----------+--------------+----------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, \n",
    "COUNT(h.name) AS hospital_count, \n",
    "c.POP2000 AS Population, \n",
    "c.POP2000/COUNT(h.name) AS people_per_hospital\n",
    "FROM counties AS c, hospitals AS h\n",
    "WHERE c.STATE_NAME='New York'\n",
    "AND ST_Intersects(h.location, c.shape)\n",
    "GROUP BY c.NAME, c.POP2000\n",
    "ORDER BY people_per_hospital DESC\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With additional detail, such as number of beds, number of doctors per hospital, you could determine a better measure for health care coverage per state and population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Window queries\n",
    "\n",
    "A common use case for mapping applications and in particular for web mapping is to select objects that fall within a rectangular region. This can be done by creating a polygon to represent the rectangle and using the `ST_Intersects` spatial predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE ST_Intersects(location, ST_WKTToSQL(\n",
    " 'POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another spatial predicate that does the same is `EnvelopesIntersect`, which can be used to select objects whose envelope intersects a rectangular region. `EnvelopesIntersect` takes as a parameter the name of the spatial column and four Double values representing the lower-left, and upper-right corners of the rectangle. This spatial predicate is simpler to use and is more efficient than `ST_Intersects` for rectangular windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE EnvelopesIntersect(location, -74.0, 42.0, -73.0, 43.0)\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this predicate is true if any portion of a line or polygon geometry falls within the specified window, parts of the line or polygon might lie outside of the window. This is generally not a problem with mapping applications, which will discard geometries that lie outside the display window.\n",
    "\n",
    "When building web-mapping applications with widely used web-mapping APIs from providers such as Google Maps, Yahoo! Maps, Bing Maps, and others, it is necessary to provide the longitude and latitude values to be used in placing custom markers on the map. You can get this information by using a query such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+\n",
      "|                name| longitude| latitude|\n",
      "+--------------------+----------+---------+\n",
      "|   Marshall Hospital|-73.678177|42.718971|\n",
      "|Southwestern Medi...|-73.206772|42.874249|\n",
      "|  Hillcrest Hospital|-73.280113|42.457863|\n",
      "+--------------------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_X(location) AS longitude, ST_Y(location) AS latitude\n",
    "FROM hospitals\n",
    "WHERE EnvelopesIntersect(location, -74.0, 42.0, -73.0, 43.0)\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Distance queries\n",
    "\n",
    "Another common spatial query is to find things within a specified distance of a particular location. You have probably used web-mapping applications to get this kind of information. You can issue SQL queries from your application for questions like:\n",
    "\n",
    "- Find customers within 10 miles of a store\n",
    "- Find ATMs within 500 meters of the current location\n",
    "- Find competitive stores within 10 kilometers of a proposed store location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial function used for these queries is `ST_Distance`, which computes the distance between the spatial values and returns a result in meters. \n",
    "\n",
    "The following query generates eight results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE ST_Intersects(location, ST_WKTToSQL(\n",
    " 'POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different way of querying the same location above is to use the `ST_Buffer` function, where a circular buffer is created around the given geometry and the desired geometries within that buffer are determined. The `ST_Buffer` function takes as parameters a spatial geometry and a distance in meters to the buffer around this spatial value. The results are the same as when you us `ST_Intersects`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|      Adventist Home|\n",
      "|      Bowne Hospital|\n",
      "|Columbia Memorial...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE\n",
    "ST_Intersects(location,\n",
    "  ST_Buffer(ST_Point(-74.237, 42.037), 46800.0))\n",
    "ORDER BY name\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query returns the distance from a specified point to each object within a 30 mile (or approximately 46800m) radius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                name|         distance|\n",
      "+--------------------+-----------------+\n",
      "|Greene County Mem...|36634.88406671601|\n",
      "|      Adventist Home|39014.09079207157|\n",
      "|Hudson River Stat...|43362.54508885234|\n",
      "+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_Distance(location, ST_Point(-74.237, 42.037)) AS distance\n",
    "FROM hospitals\n",
    "WHERE ST_Distance(location, ST_Point(-74.237, 42.037)) < 46800.0\n",
    "ORDER BY distance\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also use `ST_Buffer` to compute the spatial relation and then determine the distance as is shown in the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                name|         distance|\n",
      "+--------------------+-----------------+\n",
      "|Greene County Mem...|36634.88406671601|\n",
      "|      Adventist Home|39014.09079207157|\n",
      "|Hudson River Stat...|43362.54508885234|\n",
      "+--------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_Distance(location, ST_Point(-74.237, 42.037)) AS distance\n",
    "FROM hospitals\n",
    "WHERE\n",
    "  ST_Intersects(location,\n",
    "  ST_Buffer(ST_Point(-74.237, 42.037), 46800.0))\n",
    "ORDER BY distance\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference that you should note here is that the `ST_Buffer` function in the spatio-temporal library supports buffering of arbitrary geometries and can be used to compute in that manner. \n",
    "\n",
    "Bear in mind that:\n",
    "- The ST_Buffer query on large geometries can be expensive.\n",
    "- For a large number of geometries, you are advised to calculate the buffers separately, to store the buffers in columns, and to then operate on the stored buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------------------------------------------------------------+\n",
      "|                name|UDF:ST_Distance(location, UDF:ST_WKTToSQL(LINESTRING (-74.0 42.0, -73.0 42.0)))|\n",
      "+--------------------+-------------------------------------------------------------------------------+\n",
      "|      Avery Hospital|                                                             38777.964957148106|\n",
      "|   Hartford Hospital|                                                               38204.0148377887|\n",
      "|Springfield Munic...|                                                              39761.18673983218|\n",
      "+--------------------+-------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_Distance(location, ST_WKTToSQL(\n",
    " 'LINESTRING (-74.0 42.0, -73.0 42.0)'))\n",
    "FROM hospitals\n",
    "WHERE ST_Intersects(location, ST_Buffer(ST_WKTToSQL(\n",
    " 'LINESTRING (-74.0 42.0, -73.0 42.0)'), 46800.0))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "##  Summary\n",
    "\n",
    "In this notebook, you learnt how to query spatial data you downloaded from the IBM Watson Studio Gallery. You registered each data frame (one with data on hospitals and another with county information) as a table to run your queries on. The sample queries showed you how to determine the hospitals within a certain distance or in a polygon, to find the name of the county in which a hospital is located, or to identify the counties where the population is underserved by hospitals. The sample queries showed you how to use and combine the most common Spark SQL spatial functions in queries. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
